{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d3455",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3352e1cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from mimi import envs\n",
    "from mimi import utils\n",
    "from mimi import user_models\n",
    "from mimi import opt\n",
    "from mimi import reward_models\n",
    "from mimi import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982cca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = utils.make_tf_session(gpu_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d2380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 'sim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a264006d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join(utils.data_dir, 'cursor', user_id)\n",
    "if not os.path.exists(data_dir):\n",
    "  os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae4521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_dims = np.array([1, 1]) * 1000\n",
    "max_ep_len = 300\n",
    "speed = 0.02\n",
    "goal_dist_thresh = 0.05\n",
    "reset_delay = 0\n",
    "step_delay = 0.075\n",
    "n_user_obs_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfc33fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inv_dyn_model_init_args = [sess]\n",
    "inv_dyn_model_init_kwargs = {\n",
    "  'n_env_obs_dim': 2,\n",
    "  'n_user_obs_dim': n_user_obs_dim,\n",
    "  'n_act_dim': 2,\n",
    "  'n_layers': 2,\n",
    "  'layer_size': 64\n",
    "}\n",
    "inv_dyn_ens_init_kwargs = {\n",
    "  'buffer_size': 100,\n",
    "  'n_models': 4,\n",
    "  'temp': 1e2\n",
    "}\n",
    "user_model = user_models.SimCursorUser(\n",
    "  speed=speed, \n",
    "  inv_dyn_model_init_args=inv_dyn_model_init_args, \n",
    "  inv_dyn_model_init_kwargs=inv_dyn_model_init_kwargs,\n",
    "  inv_dyn_ens_init_kwargs=inv_dyn_ens_init_kwargs,\n",
    "  noise_std=1e-2,\n",
    "  n_user_obs_dim=n_user_obs_dim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ea12f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = envs.CursorEnv(\n",
    "  sess,\n",
    "  user_model,\n",
    "  max_ep_len=max_ep_len,\n",
    "  goal_dist_thresh=goal_dist_thresh,\n",
    "  speed=speed,\n",
    "  win_dims=win_dims,\n",
    "  reset_delay=reset_delay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b638df84",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_model_init_args = [sess]\n",
    "mi_model_init_kwargs = {\n",
    "  'n_env_obs_dim': env.n_env_obs_dim,\n",
    "  'n_user_obs_dim': env.n_user_obs_dim,\n",
    "  'n_act_dim': env.n_act_dim,\n",
    "  'n_layers': 2,\n",
    "  'layer_size': 64\n",
    "}\n",
    "mi_model_train_kwargs = {\n",
    "  'iterations': 1000,\n",
    "  'ftol': 1e-6,\n",
    "  'learning_rate': 1e-3,\n",
    "  'batch_size': 64,\n",
    "  'val_update_freq': None,\n",
    "  'verbose': False,\n",
    "  'warm_start': False\n",
    "}\n",
    "reward_model = reward_models.MIRewardModel(\n",
    "  env,\n",
    "  mi_model_init_args,\n",
    "  mi_model_init_kwargs,\n",
    "  mi_model_train_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4d1bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_rew_of_rollout(rollout):\n",
    "  goal = rollout[-1][-1]['goal']\n",
    "  rews = [-np.linalg.norm(x[0][:2]-goal) for x in rollout]\n",
    "  p = len(rollout) / env.max_ep_len\n",
    "  return p * np.mean(rews) + (1-p) * rews[-1]\n",
    "true_reward_model = lambda rollouts: np.mean([true_rew_of_rollout(rollout) for rollout in rollouts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6151e47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d233bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "intuitive_model = models.InvDynModel(*inv_dyn_model_init_args, **inv_dyn_model_init_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a49a0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_obses = np.random.random((10000, env.n_env_obs_dim))\n",
    "user_obses = np.random.normal(0, 1, (10000, env.n_user_obs_dim))\n",
    "user_obses /= np.linalg.norm(user_obses, axis=1, keepdims=True) + 1e-9\n",
    "next_env_obses = env_obses + user_obses * env.speed\n",
    "next_env_obses = np.maximum(0, next_env_obses)\n",
    "next_env_obses = np.minimum(1, next_env_obses)\n",
    "data = {\n",
    "  'env_obses': env_obses,\n",
    "  'user_obses': user_obses,\n",
    "  'next_env_obses': next_env_obses\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87d1a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = utils.split_data(data, train_frac=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cb8fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_dyn_model_train_kwargs = {\n",
    "  'iterations': 10000,\n",
    "  'ftol': 1e-6,\n",
    "  'learning_rate': 1e-3,\n",
    "  'batch_size': 64,\n",
    "  'val_update_freq': 1000,\n",
    "  'verbose': True,\n",
    "  'warm_start': False\n",
    "}\n",
    "intuitive_model.train(data, **inv_dyn_model_train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2f4e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_model.inv_dyn_model.models[0] = intuitive_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c043b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ed8231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rand_policy():\n",
    "  ang = np.random.random() * 2*np.pi\n",
    "  return lambda obs: utils.rotate_vec(env.extract_user_obses(obs[np.newaxis])[0], ang)\n",
    "\n",
    "n_policies = 5\n",
    "n_rollouts_per_policy = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b4651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_rollouts = [[] for _ in range(n_policies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe644945",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(n_policies):\n",
    "  policy = make_rand_policy()\n",
    "  while len(baseline_rollouts[i]) < n_rollouts_per_policy:\n",
    "    rollout = utils.run_ep(policy, env, render=True)\n",
    "    baseline_rollouts[i].append(rollout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27ea236",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_path = os.path.join(data_dir, 'baseline_rollouts.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d714b611",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(baseline_path, 'wb') as f:\n",
    "  pickle.dump(baseline_rollouts, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75660df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_reward_model(sum(baseline_rollouts, []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e8a43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba3552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_env = envs.RewardModelCursorEnv(\n",
    "  sess,\n",
    "  user_model,\n",
    "  max_ep_len=max_ep_len,\n",
    "  goal_dist_thresh=goal_dist_thresh,\n",
    "  speed=speed,\n",
    "  win_dims=win_dims,\n",
    "  reset_delay=reset_delay,\n",
    "  update_freq=10,\n",
    "  buffer_size=10\n",
    ")\n",
    "ppo_env.set_reward_model(reward_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fe5bd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ppo_kwargs = {\n",
    "  'policy_kwargs': {'net_arch': [64, 64]}\n",
    "}\n",
    "ppo_model = PPO(\"MlpPolicy\", ppo_env, verbose=1, **ppo_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0f7a6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ppo_model.learn(total_timesteps=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb14223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_policy = lambda obs: ppo_model.predict(obs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3e0065",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_rollouts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26462905",
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(ppo_rollouts) < 10:\n",
    "  rollout = utils.run_ep(ppo_policy, ppo_env, render=True)\n",
    "  ppo_rollouts.append(rollout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0d5fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_reward_model(ppo_rollouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532f9f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(ppo_env.reward_model.compute_step_rewards(ppo_rollouts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba07fe7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba41bfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_obses = user_obses[np.random.choice(np.arange(0, len(user_obses), 1), 100), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8199d5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_optimizer = opt.GP(\n",
    "  env,\n",
    "  reward_model,\n",
    "  param_bounds=(-1., 1.),\n",
    "  #param_bounds=(0, 2*np.pi),\n",
    "  #n_policy_params=1,\n",
    "  #W_from_w=(lambda w: np.array([[np.cos(w[0]), -np.sin(w[0])], [np.sin(w[0]), np.cos(w[0])]]))\n",
    "  kernel_obses=kernel_obses\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fb4ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_min_kwargs = {\n",
    "  'n_initial_points': 5\n",
    "}\n",
    "ep_kwargs = {}\n",
    "n_eps_per_pol = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10261e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x0, _, y0 = zip(*eval_data_of_pol)\n",
    "#gp_min_kwargs.update({'x0': list(x0), 'y0': list(y0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed369c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_policy, res = gp_optimizer.run(\n",
    "  n_pols=500,\n",
    "  n_eps_per_pol=n_eps_per_pol,\n",
    "  gp_min_kwargs=gp_min_kwargs,\n",
    "  ep_kwargs=ep_kwargs,\n",
    "  reward_model_train_kwargs=mi_model_train_kwargs,\n",
    "  verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5396785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_data_of_pol.extend(gp_optimizer.eval_data_of_pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557215ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_of_pol = gp_optimizer.eval_data_of_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59ca574",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_results_path = os.path.join(data_dir, 'gp_results.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2452b79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(gp_results_path, 'wb') as f:\n",
    "  pickle.dump(eval_data_of_pol, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a11508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e767e9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(utils.data_dir, 'cursor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708c96fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_evals = []\n",
    "pols = []\n",
    "\n",
    "for user_id in ['sim']:\n",
    "  user_path = os.path.join(data_dir, str(user_id))\n",
    "  if os.path.exists(user_path):\n",
    "    baseline_path = os.path.join(user_path, 'baseline_rollouts.pkl')\n",
    "    with open(baseline_path, 'rb') as f:\n",
    "      baseline_rollouts = pickle.load(f)\n",
    "    baseline_rollouts = sum(baseline_rollouts, [])\n",
    "    baseline_true_rewards = true_reward_model(baseline_rollouts)\n",
    "    \n",
    "    gp_results_path = os.path.join(user_path, 'gp_results.pkl')\n",
    "    with open(gp_results_path, 'rb') as f:\n",
    "      eval_data_of_pol = pickle.load(f)\n",
    "    true_rews_of_pol = [[true_reward_model([rollout]) for rollout in eval_data[1]] for eval_data in eval_data_of_pol]\n",
    "    true_rew_of_pol = [true_reward_model(eval_data[1]) for eval_data in eval_data_of_pol]\n",
    "    rew_of_pol = [eval_data[2] for eval_data in eval_data_of_pol]\n",
    "    n_eps_of_pol = [len(eval_data[1]) for eval_data in eval_data_of_pol]\n",
    "    \n",
    "    true_rews = sum(true_rews_of_pol, [])\n",
    "    perf_evals.append({\n",
    "      'true_rews': true_rews, \n",
    "      'true_rew': true_rew_of_pol, \n",
    "      'rew': rew_of_pol,\n",
    "      'n_eps': np.cumsum(n_eps_of_pol),\n",
    "      'xs': np.cumsum(np.ones(len(true_rews)))-1,\n",
    "      'baseline_true_reward': np.mean(baseline_true_rewards)\n",
    "    })\n",
    "    pols.append(eval_data_of_pol[-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a558a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ded559",
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_angs = [[pol[0] for pol in pols]]\n",
    "\n",
    "N = 20\n",
    "bottom = 8\n",
    "max_height = 4\n",
    "\n",
    "radii, theta = plt.hist(pol_angs, bins=20)[:2]\n",
    "theta = np.mean(list(zip(theta[:-1], theta[1:])), axis=1)\n",
    "width = (2*np.pi) / N\n",
    "\n",
    "ax = plt.subplot(111, polar=True)\n",
    "bars = ax.bar(theta, radii, width=width, color='orange')\n",
    "\n",
    "plt.title('Emergent Interfaces')\n",
    "plt.savefig(os.path.join(data_dir, 'sim-learned-int.pdf'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0b6332",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = sum([perf_eval['true_rew'] for perf_eval in perf_evals], [])\n",
    "ys = sum([perf_eval['rew'] for perf_eval in perf_evals], [])\n",
    "rho = scipy.stats.spearmanr(xs, ys)[0]\n",
    "plt.title(r'True Reward vs. Mutual Information Reward ($\\rho = %0.2f$)' % rho)\n",
    "plt.xlabel('True Reward (Avg. Distance to Target)')\n",
    "plt.ylabel(r\"$\\mathcal{I}(\\mathbf{x}_t, (\\mathbf{s}_t, \\mathbf{s}_{t+1}))$\")\n",
    "plt.scatter(\n",
    "  xs, \n",
    "  ys,\n",
    "  color='orange',\n",
    "  s=50,\n",
    "  alpha=0.5\n",
    ")\n",
    "plt.xticks(fontsize=10)\n",
    "plt.savefig(os.path.join(data_dir, 'sim-truerew-vs-mi.pdf'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff464f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Mutual Information Reward')\n",
    "plt.xlabel('Number of Online Training Episodes')\n",
    "plt.ylabel(r\"$\\mathcal{I}(\\mathbf{x}_t, (\\mathbf{s}_t, \\mathbf{s}_{t+1}))$\")\n",
    "utils.plot_perf_evals(perf_evals, 'n_eps', 'rew', label='MIMI (Ours)', smooth_win=1, color='teal')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(os.path.join(data_dir, 'sim-study-mi-vs-eps.pdf'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2b362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('User Study: 2D Cursor Control with Perturbed Mouse')\n",
    "plt.xlabel('Number of Online Training Episodes')\n",
    "plt.ylabel('True Reward (Avg. Distance to Target)')\n",
    "utils.plot_perf_evals(perf_evals, 'xs', 'true_rews', label='MIMI (Ours)', smooth_win=1, color='orange')\n",
    "plt.axhline(y=np.mean([perf['baseline_true_reward'] for perf in perf_evals]), linestyle='--', color='gray', label='Random Interfaces (Baseline)')\n",
    "plt.axhline(y=-0.0726392950518139, linestyle='--', color='green', label='Oracle')\n",
    "plt.legend(loc='lower right')\n",
    "#plt.ylim([-0.14, None])\n",
    "plt.savefig(os.path.join(data_dir, 'sim-truerew-vs-eps.pdf'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee581f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trajs(eval_data_of_pol):\n",
    "  traj = np.array([x[0][:2] for eval_data in eval_data_of_pol for rollout in eval_data[1] for x in rollout])\n",
    "  plt.scatter(traj[:, 0], traj[:, 1], alpha=0.25, linewidth=0, color='gray')\n",
    "  plt.gca().set_aspect('equal', adjustable='box')\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  \n",
    "def plot_before_trajs(eval_data_of_pol):\n",
    "  plt.title('<50 Training Episodes')\n",
    "  plot_trajs(eval_data_of_pol[:5])\n",
    "  \n",
    "def plot_after_trajs(eval_data_of_pol):\n",
    "  plt.title('>150 Training Episodes')\n",
    "  plot_trajs(eval_data_of_pol[15:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d96a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'sim', 'gp_results.pkl'), 'rb') as f:\n",
    "  eval_data_of_pol = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a69101",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_before_trajs(eval_data_of_pol)\n",
    "plt.savefig(os.path.join(data_dir, 'sim-before-trajs.pdf'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4693547",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_after_trajs(eval_data_of_pol)\n",
    "plt.savefig(os.path.join(data_dir, 'sim-after-trajs.pdf'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeadbf29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
